### ELO 评级系统

在对抗性游戏中，累积环境奖励可能**不是一个有意义的指标**来跟踪学习进度。

这是因为累积奖励**完全取决于对手的技能水平**。

一个特定技能水平的Agent（智能体）对抗较差或较强的Agent（智能体）时，会获得更多或更少的奖励。

相反，最好使用ELO评级系统，这是一种计算**两个玩家在零和游戏中相对技能水平**的方法。

如果训练正确进行，**这个值应该会稳定增加**。

## 什么是零和游戏？
零和游戏是指**每个玩家的效用增益或损失恰好被对手的效用增益或损失所平衡的游戏**。

简单来说，当一个Agent（智能体）获得+1.0奖励时，其对手获得-1.0奖励，我们就面临一个零和游戏。

例如，网球是一种零和游戏：如果你赢得了这一分，你获得+1.0奖励，而你的对手获得-1.0奖励。

## ELO 评级系统如何工作
- 每个玩家**都有一个初始的ELO评分**。它在`initial_elo`训练配置超参数中定义。

- **两个玩家之间的评分差异**作为比赛结果的预测指标。

![ELO示例](images/elo_example.png)
*例如，如果玩家A的ELO评分为2100，而玩家B的ELO评分为1800，则玩家A获胜的概率为85%，而玩家B的概率为15%。*

- 我们使用以下公式计算**每个玩家的预期得分**：

![ELO预期得分公式](images/elo_expected_score_formula.png)

- 比赛结束后，根据结果**我们更新玩家的实际ELO评分**，我们使用线性调整，比例取决于玩家表现超过或低于预期的程度。
  获胜的玩家从失败的玩家那里获得分数：
  - 如果*高评分玩家获胜* → 从低评分玩家那里获得**少量分数**。
  - 如果*低评分玩家获胜* → 从高评分玩家那里获得**大量分数**。
  - 如果*平局* → 低评分玩家从高评分玩家那里获得**少量分数**。

- 我们使用以下公式更新玩家评分：

![ELO评分更新公式](images/elo_score_update_formula.png)

### 网球示例

- 我们开始训练我们的Agent（智能体）。
- 他们的技能相同。所以我们使用参数`initial_elo = 1200.0`为每个Agent（智能体）定义ELO评分。

我们计算预期得分E：
Ea = 0.5
Eb = 0.5

这意味着每个玩家有50%的几率赢得这一分。

如果A获胜，新的评分R将是：

Ra = 1200 + 16 * (1 - 0.5) → 1208

Rb = 1200 + 16 * (0 - 0.5) → 1192

现在，玩家A的ELO评分为1208，而玩家B的ELO评分为1192。因此，玩家A现在**比玩家B稍微强一些**。